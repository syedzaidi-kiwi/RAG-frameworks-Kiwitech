{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syedzaidi-kiwi/RAG-frameworks-Kiwitech/blob/main/RAG_with_LlamaIndex_and_Gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf9f19f3",
      "metadata": {
        "id": "bf9f19f3"
      },
      "source": [
        "# Gradient Model Adapter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8cfc62e",
      "metadata": {
        "id": "c8cfc62e"
      },
      "outputs": [],
      "source": [
        "%pip install llama-index-embeddings-langchain\n",
        "%pip install llama-index-llms-gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79a726c5",
      "metadata": {
        "id": "79a726c5"
      },
      "outputs": [],
      "source": [
        "%pip install llama-index --quiet\n",
        "%pip install gradientai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c2b0d5d",
      "metadata": {
        "id": "1c2b0d5d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GRADIENT_ACCESS_TOKEN\"] = \"{GRADIENT_ACCESS_TOKEN}\"\n",
        "os.environ[\"GRADIENT_WORKSPACE_ID\"] = \"{GRADIENT_WORKSPACE_ID}\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a602a2a",
      "metadata": {
        "id": "9a602a2a"
      },
      "source": [
        "## Flow 1: Query Gradient LLM directly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4baffaa2",
      "metadata": {
        "id": "4baffaa2"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.gradient import GradientModelAdapterLLM\n",
        "\n",
        "llm = GradientModelAdapterLLM(\n",
        "    model_adapter_id=\"{YOUR_MODEL_ADAPTER_ID}\",\n",
        "    max_tokens=400,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7039a65",
      "metadata": {
        "id": "e7039a65"
      },
      "outputs": [],
      "source": [
        "result = llm.complete(\"Can you tell me about large language models?\")\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1112e828",
      "metadata": {
        "id": "1112e828"
      },
      "source": [
        "## Flow 2: Retrieval Augmented Generation (RAG) with Gradient LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cacff36a",
      "metadata": {
        "id": "cacff36a"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efa8539a",
      "metadata": {
        "id": "efa8539a"
      },
      "source": [
        "#### Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "403e7697",
      "metadata": {
        "id": "403e7697"
      },
      "outputs": [],
      "source": [
        "!mkdir -p 'data/paul_graham/'\n",
        "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1edd41d1",
      "metadata": {
        "id": "1edd41d1"
      },
      "source": [
        "### Load Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5941151",
      "metadata": {
        "id": "c5941151"
      },
      "outputs": [],
      "source": [
        "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7df4407f",
      "metadata": {
        "id": "7df4407f"
      },
      "source": [
        "### Configure Gradient LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dec73a6b",
      "metadata": {
        "id": "dec73a6b"
      },
      "outputs": [],
      "source": [
        "embed_model = LangchainEmbedding(HuggingFaceEmbeddings())\n",
        "splitter = SentenceSplitter(chunk_size=1024)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a131a8e",
      "metadata": {
        "id": "7a131a8e"
      },
      "source": [
        "### Setup and Query Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9b10269",
      "metadata": {
        "id": "c9b10269"
      },
      "outputs": [],
      "source": [
        "index = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    transformations=[splitter],\n",
        "    embed_model=embed_model,\n",
        ")\n",
        "query_engine = index.as_query_engine(llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac73eb65",
      "metadata": {
        "id": "ac73eb65"
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(\n",
        "    \"What did the author do after his time at Y Combinator?\"\n",
        ")\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "vscode": {
      "interpreter": {
        "hash": "5ae9fa2777630f93d325d67fd0c37f7375ed1afcb20dd85f425eb8692a47ff3f"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}